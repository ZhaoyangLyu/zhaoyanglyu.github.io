<!doctype html>
<html lang="en" class="no-js">
    <head>
        <meta charset="utf-8">
        <!-- begin SEO -->
        <title>About me - Zhaoyang Lyu</title>
        <meta property="og:locale" content="en-US">
        <meta property="og:site_name" content="Zhaoyang Lyu">
        <meta property="og:title" content="About me">
        <link rel="canonical" href="https://zhaoyanglyu.github.io//">
        <meta property="og:url" content="https://zhaoyanglyu.github.io//">
        <meta property="og:description" content="About me">
        <script type="application/ld+json">
            {
                "@context": "http://schema.org",
                "@type": "Person",
                "name": "Zhaoyang Lyu",
                "url": "https://zhaoyanglyu.github.io/",
                "sameAs": null
            }</script>
        <!-- end SEO -->
        <link href="https://zhaoyanglyu.github.io//feed.xml" type="application/atom+xml" rel="alternate" title="Zhaoyang Lyu Feed">
        <!-- http://t.co/dKP3o1e -->
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script>
            document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
        </script>
        <!-- For all browsers -->
        <link rel="stylesheet" href="assets/css/main.css">
        <meta http-equiv="cleartype" content="on">
        <!-- start custom head snippets -->
        <!-- <link rel="apple-touch-icon" sizes="57x57" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="60x60" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="72x72" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="76x76" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="114x114" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="120x120" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="144x144" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="152x152" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
        <link rel="apple-touch-icon" sizes="180x180" href="https://zhaoyanglyu.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
        <link rel="icon" type="image/png" href="https://zhaoyanglyu.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
        <link rel="icon" type="image/png" href="https://zhaoyanglyu.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
        <link rel="icon" type="image/png" href="https://zhaoyanglyu.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
        <link rel="icon" type="image/png" href="https://zhaoyanglyu.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
        <link rel="manifest" href="https://zhaoyanglyu.github.io/images/manifest.json?v=M44lzPylqQ">
        <link rel="mask-icon" href="https://zhaoyanglyu.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
        <link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ"> -->
        <!-- <meta name="msapplication-TileColor" content="#000000">
        <meta name="msapplication-TileImage" content="https://zhaoyanglyu.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
        <meta name="msapplication-config" content="https://zhaoyanglyu.github.io/images/browserconfig.xml?v=M44lzPylqQ">
        <meta name="theme-color" content="#ffffff"> -->
        <link rel="stylesheet" href="assets/css/academicons.css"/>
        <script type="text/x-mathjax-config">
             MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); 
        </script>
        <script type="text/x-mathjax-config">
             MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); 
        </script>
        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
        <!-- end custom head snippets -->
    </head>
    <body>
        <!--[if lt IE 9]><div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->
        <div class="masthead">
            <div class="masthead__inner-wrap">
                <div class="masthead__menu">
                    <nav id="site-nav" class="greedy-nav">
                        <button>
                            <div class="navicon"></div>
                        </button>
                        <ul class="visible-links">
                            <li class="masthead__menu-item masthead__menu-item--lg">
                                <a href="https://zhaoyanglyu.github.io/">Zhaoyang Lyu</a>
                            </li>
                        </ul>
                        <ul class="hidden-links hidden"></ul>
                    </nav>
                </div>
            </div>
        </div>
        <div id="main" role="main">
            <div class="sidebar sticky">
                <div itemscope itemtype="http://schema.org/Person">
                    <div class="author__avatar">
                        <img src="images/me.jpg" class="author__avatar" alt="Zhaoyang Lyu ÂêïÁÖßÈò≥">
                    </div>
                    <div class="author__content">
                        <h3 class="author__name">Zhaoyang Lyu ÂêïÁÖßÈò≥</h3>
                        <p class="author__bio">Researcher @ Shanghai AI Lab</p>
                    </div>
                    <div class="author__urls-wrapper">
                        <button class="btn btn--inverse">Follow</button>
                        <ul class="author__urls social-icons">
                            <li>
                                <i class="fa fa-fw fa-map-marker-alt" aria-hidden="true"></i>
                                Shanghai
                            </li>
                            <li>
                                <a href="mailto:lvzhaoyang@pjlab.org.cn">
                                    <i class="fas fa-fw fa-envelope" aria-hidden="true"></i>
                                    Email
                                </a>
                            </li>
                            <!-- <li>
                                <a href="https://twitter.com/wangtai97">
                                    <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i>
                                    Twitter
                                </a>
                            </li> -->
                            <!-- <li>
                                <a href="https://www.linkedin.com/in/Ê≥∞-Áéã-2b2738147">
                                    <i class="fab fa-fw fa-linkedin" aria-hidden="true"></i>
                                    LinkedIn
                                </a>
                            </li> -->
                            <li>
                                <a href="https://github.com/ZhaoyangLyu">
                                    <i class="fab fa-fw fa-github" aria-hidden="true"></i>
                                    Github
                                </a>
                            </li>
                            <li>
                                <a href="https://scholar.google.com.hk/citations?user=gkXFhbwAAAAJ&hl=en">
                                    <i class="fas fa-fw fa-graduation-cap"></i>
                                    Google Scholar
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
            <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
                <meta itemprop="headline" content="About me">
                <meta itemprop="description" content="About me">
                <div class="page__inner-wrap">
                    <header>
                        <h1 class="page__title" itemprop="headline">About me</h1>
                    </header>
                    <section class="page__content" itemprop="text">
                        <p>
                            I am a researcher with Shanghai AI Laboratory, working in a research group on <a href="https://idc-sh.github.io/#/">Content Generation and Digitization</a>. I received my Ph.D. (2018-2022) from Multimedia Laboratory (<a href="http://mmlab.ie.cuhk.edu.hk/">MMLab</a>) at CUHK, advised by Prof.Dahua Lin. I obtained my Bachelor's Degree (2014-2018) at Xi'an Jiaotong University. 
                            <!-- My research focus on 3D content generation, cinluding
                            
                            . I am excited about all the vision or AI technologies that can change people‚Äôs lifestyles, for example, building intelligent agents that can interact with us. My current research is mainly focused on general 3D perception, including different modalities, tasks and scenarios. I am also interested in other extensive 3D vision research and their robotic applications. -->
                        </p>
                        <h2 id="news">News</h2>
                        <!-- <ul>
                            <li>
                                [2022/07] <a href="https://arxiv.org/abs/2207.12988">DfM</a>
                                , our recent study on 3D perception from monocular videos, is accepted by <a href="https://eccv2022.ecva.net/">ECCV 2022</a>
                                .
                            </li>
                            <li>
                                [2022/06] A simple multi-view baseline, <a href="https://arxiv.org/abs/2207.12716">MV-FCOS3D++</a>
                                , obtained the runner-up in the <a href="https://cvpr2022.wad.vision/">Waymo Camera-Only 3D Detection Challenge</a>
                                with few bells-and-whistles. Code is available <a href="https://github.com/Tai-Wang/Depth-from-Motion">here</a>
                                .
                            </li>
                            <li>
                                [2021/10] <a href="https://arxiv.org/abs/2104.10956">FCOS3D</a>
                                got the best paper award on the <a href="https://sites.google.com/unitn.it/3dodi/home">ICCV 3DODI workshop</a>
                                ! Thanks for the recognition!
                            </li>
                            <li>
                                [2021/09] One paper is accepted by <a href="https://nips.cc/">NeurIPS 2021</a>
                                .
                            </li>
                            <li>
                                [2021/09] <a href="https://arxiv.org/abs/2107.14160">PGD</a>
                                , our follow-up work of FCOS3D, is accepted by <a href="https://www.robot-learning.org/">CoRL 2021</a>
                                .
                            </li>
                            <li>
                                [2021/02] Our further research on voxel representation learning, <a href="https://arxiv.org/abs/2011.10033">Cylinder3D</a>
                                , is accepted by <a href="https://cvpr2021.thecvf.com/">CVPR 2021</a>
                                . We also obtained the runner-up in the <a href="https://www.nuscenes.org/lidar-segmentation?externalData=all&amp;mapData=all&amp;modalities=Any">nuScenes LiDAR Segmentation Challenge</a>
                                .
                            </li>
                            <li>
                                [2020/12] MMDet3D Team wins the Best PKL Award and best vision-only results in the 3rd <a href="https://www.nuscenes.org/object-detection?externalData=all&amp;mapData=all&amp;modalities=Any">nuScenes detection challenge</a>
                                of 5th AI Driving Olympics, <a href="https://nips.cc/">NeurIPS 2020</a>
                                .
                            </li>
                            <li>
                                [2020/11] We release the full technical report for our previously developed LiDAR annotation tool, <a href="https://arxiv.org/abs/2011.10174">FLAVA</a>
                                .
                            </li>
                            <li>
                                [2020/10] <a href="https://arxiv.org/abs/2004.02724">Reconfigurable Voxels</a>
                                is accepted to <a href="https://sites.google.com/robot-learning.org/corl2020">CoRL 2020</a>
                                .
                            </li>
                            <li>
                                [2020/07] <a href="https://github.com/open-mmlab/mmdetection3d">MMDetection3D</a>
                                is finally released! Fork this versatile codebase and have a try, pushing forward this field to general 3D detection together.
                            </li>
                        </ul> -->
                        <h2 id="education">Education</h2>
                        <dl>
                            <dt>
                                <img src="images/cuhk.png" width="80" height="80" alt="cuhk" align="left"/>
                            </dt>
                            <dt> &nbsp &nbsp The Chinese University of Hong Kong (CUHK)</dt>
                            <dd> &nbsp &nbsp August 2018 - July 2022</dd>
                            <dd> &nbsp &nbsp Ph.D. in Information Engineering</dd>
                            <dt>
                                <img src="images/xjtu.png" width="80" height="80" alt="zju" align="left"/>
                            </dt>
                            <dt> &nbsp &nbsp Xi'an Jiaotong University (XJTU)</dt>
                            <dd> &nbsp &nbsp August 2014 - July 2018</dd>
                            <dd> &nbsp &nbsp B.S. in Physics (Experimental Class)</dd>
                        </dl>
                        <h2 id="publications">Publications</h2>
                        <dl>
                            <dt>
                                <strong>3D Content Generation</strong>
                                <br/>
                            </dt>
                            
                            <dt>
                                <img src="images/paper_cvpr2023_slide.png" width="180" height="110" alt="slide" align="left"/>
                            </dt>
                            <dt>
                                &nbsp &nbsp SLIDE: Controllable Mesh Generation Through Sparse Latent <br/> &nbsp &nbsp Point Diffusion Models
                            </dt>
                            <dd>
                                &nbsp &nbsp <strong>Zhaoyang Lyu</strong>, Jinyi Wang, Yuwei An, Ya Zhang, Dahua Lin, Bo Dai
                            </dd>
                            <dd>
                                &nbsp &nbsp IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>
                                ) 2023
                            </dd>
                            <dd>
                                &nbsp &nbsp <a href="https://arxiv.org/abs/2303.07938">[Paper]</a>
                                <a href="https://github.com/SLIDE-3D/SLIDE">[Code]</a>
                                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:5VyxJ5Yfp90J:scholar.google.com/&output=citation&scisdr=ClHXBVKSEL-qivOLrpk:AFWwaeYAAAAAZW6NtplK8pv3YiAS_8dasj-p4aE&scisig=AFWwaeYAAAAAZW6Nts8d6F9UVaWNDsK7TsaQv5o&scisf=4&ct=citation&cd=-1&hl=en">[Bibtex]</a>
                            </dd>

                            <dt>
                                <img src="images/paper_iclr2022_pdr.png" width="180" height="110" alt="pdr" align="left"/>
                            </dt>
                            <dt>
                                &nbsp &nbsp A Conditional Point Diffusion-Refinement Paradigm for 3D <br/> &nbsp &nbsp Point Cloud Completion
                            </dt>
                            <dd>
                                &nbsp &nbsp <strong>Zhaoyang Lyu</strong>, Zhifeng Kong, Xudong Xu, Liang Pan, Dahua Lin
                            </dd>
                            <dd>
                                &nbsp &nbsp International Conference on Learning Representations (<strong>ICLR</strong>
                                ) 2022
                            </dd>
                            <dd>
                                &nbsp &nbsp <a href="https://arxiv.org/abs/2112.03530">[Paper]</a>
                                <a href="https://github.com/ZhaoyangLyu/Point_Diffusion_Refinement">[Code]</a>
                                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:aUKD6FNT2zoJ:scholar.google.com/&output=citation&scisdr=ClHXBVKSELiiwPPdTUo:AFWwaeYAAAAAZW7bVUpivING1LMlUl1w4e61Cnw&scisig=AFWwaeYAAAAAZW7bVSLMxkj_c3MV-espkdT1nss&scisf=4&ct=citation&cd=-1&hl=en">[Bibtex]</a>
                            </dd>

                            <dt>
                                <img src="images/paper_iclr2023_matlaber.png" width="180" height="110" alt="matlaber" align="left"/>
                            </dt>
                            <dt>
                                &nbsp &nbsp MATLABER: Material-Aware Text-to-3D via LAtent BRDF auto-EncodeR
                            </dt>
                            <dd>
                                &nbsp &nbsp Xudong Xu, <strong>Zhaoyang Lyu</strong>, Xingang Pan, Bo Dai
                            </dd>
                            <dd>
                                &nbsp &nbsp arXiv preprint
                            </dd>
                            <dd>
                                &nbsp &nbsp <a href="https://arxiv.org/abs/2308.09278">[Paper]</a>
                                <a href="https://github.com/SheldonTsui/Matlaber">[Code]</a>
                                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Qi5tms461wcJ:scholar.google.com/&output=citation&scisdr=ClHXBVKSEL-qivPbksQ:AFWwaeYAAAAAZW7disR99W8cF6j3vTbj_EKUpCE&scisig=AFWwaeYAAAAAZW7diuOn5ked1An2Ge9_G6dlulU&scisf=4&ct=citation&cd=-1&hl=en">[Bibtex]</a>
                            </dd>


                            <dt>
                                <strong>Neural Network Robustness</strong>
                                <br/>
                            </dt>

                            <dt>
                                <img src="images/paper_icml2019_popqorn.png" width="170" height="110" alt="popqorn" align="left"/>
                            </dt>
                            <dt>
                                &nbsp &nbsp POPQORN: Quantifying robustness of recurrent neural networks
                            </dt>
                            <dd>
                                &nbsp &nbsp Ching-Yun Ko, <strong>Zhaoyang Lyu</strong> (Equal Contribution), Lily Weng, Luca Daniel, Ngai Wong, Dahua Lin
                            </dd>
                            <dd>
                                &nbsp &nbsp International Conference on Machine Learning (<strong>ICML</strong>
                                ) 2019
                            </dd>
                            <dd>
                                &nbsp &nbsp <a href="https://arxiv.org/abs/1905.07387">[Paper]</a>
                                <a href="https://github.com/ZhaoyangLyu/POPQORN">[Code]</a>
                                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:BJWo6ndW1SgJ:scholar.google.com/&output=citation&scisdr=ClHXBVKSELiiwPPjuY0:AFWwaeYAAAAAZW7loY1fst2WeHf1ph7-38ZJEIU&scisig=AFWwaeYAAAAAZW7loYyG08YyE91aOIFeXJGEkWA&scisf=4&ct=citation&cd=-1&hl=en">[Bibtex]</a>
                            </dd>

                            <dt>
                                <img src="images/paper_aaai2020_frown.png" width="170" height="110" alt="popqorn" align="left"/>
                            </dt>
                            <dt>
                                &nbsp &nbsp Fastened crown: Tightened neural network robustness certificates
                            </dt>
                            <dd>
                                &nbsp &nbsp <strong>Zhaoyang Lyu</strong>, Ching-Yun Ko, Zhifeng Kong, Ngai Wong, Dahua Lin, Luca Daniel
                            </dd>
                            <dd>
                                &nbsp &nbsp AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>
                                ) 2020
                            </dd>
                            <dd>
                                &nbsp &nbsp <a href="https://arxiv.org/abs/1912.00574">[Paper]</a>
                                <a href="https://github.com/ZhaoyangLyu/FROWN">[Code]</a>
                                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:X1oDsS2vN5oJ:scholar.google.com/&output=citation&scisdr=ClHXBVKSEL-qivPuRlM:AFWwaeYAAAAAZW7oXlM3sKkxlnai0QBycrA9oV8&scisig=AFWwaeYAAAAAZW7oXq2w2WUpnX9vueQHNQVNbIM&scisf=4&ct=citation&cd=-1&hl=en">[Bibtex]</a>
                            </dd>

                            <dt>
                                <img src="images/paper_cvpr2021_verify.png" width="170" height="110" alt="popqorn" align="left"/>
                            </dt>
                            <dt>
                                &nbsp &nbsp Towards evaluating and training verifiably robust neural networks
                            </dt>
                            <dd>
                                &nbsp &nbsp <strong>Zhaoyang Lyu</strong>, Minghao Guo, Tong Wu, Guodong Xu, Kehuan Zhang, Dahua Lin
                            </dd>
                            <dd>
                                &nbsp &nbsp IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>
                                ) 2021
                            </dd>
                            <dd>
                                &nbsp &nbsp <a href="https://arxiv.org/abs/2104.00447">[Paper]</a>
                                <a href="https://github.com/ZhaoyangLyu/VerifiablyRobustNN">[Code]</a>
                                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:_XnrvG5lAm4J:scholar.google.com/&output=citation&scisdr=ClHXBVKSELiiwPPsVtg:AFWwaeYAAAAAZW7qTtiWGuFQlFZV_BhyCy37PA8&scisig=AFWwaeYAAAAAZW7qTuBLbMRxfZyoWmoXXH9bsqA&scisf=4&ct=citation&cd=-1&hl=en">[Bibtex]</a>
                            </dd>

                        <h2 id="research-projects">Research Projects</h2>
                        <dl>
                            <dt>
                                <img src="../images/mmdet3d.gif" width="110" height="110" alt="mmdet3d" align="left"/>
                            </dt>
                            <dt>MMDetection3D: The Next-Generation Platform for General 3D Detection</dt>
                            <dd>A versatile, open-source 3D object detection toolbox based on PyTorch</dd>
                            <dd>MMDetection3D Contributors</dd>
                            <dd>May 2020 ‚Äì Now</dd>
                            <dd>
                                <a href="https://github.com/open-mmlab/mmdetection3d">[Code]</a>
                                <a href="https://mmdetection3d.readthedocs.io/en/latest/">[Doc]</a>
                                <a href="https://drive.google.com/file/d/1X24zBeM0dwol10CcKSN_SkIolhopsA85/view?usp=sharing">[Bibtex]</a>
                            </dd>
                            <dt>
                                <img src="../images/s2mesh.png" width="110" height="110" alt="s2mesh" align="left"/>
                            </dt>
                            <dt>Spherical Convolutional Networks for 3D Mesh Processing</dt>
                            <dd>New approaches to generating 3D meshes from scratch with S2 parametrization &amp;extended spherical CNNs</dd>
                            <dd>
                                <strong>Zhaoyang Lyu</strong>
                                , Weiwei Zhou and Zicheng Liao
                            </dd>
                            <dd>Under revision and further development</dd>
                            <dd>Mar 2018 ‚Äì Nov 2018</dd>
                        </dl>
                        <h2 id="experience">Experience</h2>
                        <dl>
                            <dt>
                                <img src="../images/shlab.jpg" width="80" height="85" alt="shlab" align="left"/>
                            </dt>
                            <dt>Visiting Scholar, Shanghai AI Laboratory</dt>
                            <dd>July 2020 - Now. ¬†Advisor: Jiangmiao Pang, Kai Chen</dd>
                            <dd>Focus: The next-generation platform for general 3D perception</dd>
                            <dt>
                                <img src="../images/sensetime.jpg" width="80" height="90" alt="sensetime" align="left"/>
                            </dt>
                            <dt>Adjunct Researcher, Sensetime</dt>
                            <dd>Nov. 2019 - June 2020. ¬†Advisor: Conghui He, Zhe Wang, Jianping Shi</dd>
                            <dd>Focus: Efficient annotation of LiDAR point clouds, development of LiDAR perception system</dd>
                            <dt>
                                <img src="../images/cuhk.png" width="80" height="90" alt="cuhk" align="left"/>
                            </dt>
                            <dt>Junior Research Assistant, The Chinese University of Hong Kong (CUHK)</dt>
                            <dd>Feb. 2019 - May 2019. ¬†Advisor: Dahua Lin</dd>
                            <dd>Focus: Real-time 3D object detection in autonomous driving</dd>
                            <dt>
                                <img src="../images/AZFT.png" width="80" height="90" alt="AZFT" align="left"/>
                            </dt>
                            <dt>Research Intern, Alibaba-ZJU Joint Institute of Frontier Technologies (AZFT)</dt>
                            <dd>Dec. 2017 - June 2019. ¬†Advisor: Zicheng Liao, Gang Wang. I also worked with Dr. Lechao Cheng.</dd>
                            <dd>Focus: Joint analysis of 2D Images and 3D Shapes with machine learning approaches</dd>
                        </dl>
                        <h2 id="selected-awards">Selected Awards</h2>
                        <ul>
                            <li>
                                Runner-up of <a href="https://cvpr2022.wad.vision/">Waymo Camera-Only 3D Detection Challenge</a>
                                , CVPR 2022
                            </li>
                            <li>
                                Best Paper Award of <a href="https://sites.google.com/unitn.it/3dodi/home">Workshop on 3D Object Detection from Images</a>
                                , ICCV 2021
                            </li>
                            <li>
                                1st place of vision-only track and best PKL award of overall track, <a href="https://www.nuscenes.org/object-detection?externalData=all&amp;mapData=all&amp;modalities=Any">NuScenes 3D Detection Challenge</a>
                                , NeurIPS 2020
                            </li>
                            <li>
                                Runner-up of <a href="https://www.nuscenes.org/lidar-segmentation?externalData=all&amp;mapData=all&amp;modalities=Any">NuScenes LiDAR Segmentation Challenge</a>
                                , NeurIPS 2020
                            </li>
                            <li>
                                Gold Medal of Kaggle Competition (Top 1% of <a href="https://www.nuscenes.org/lidar-segmentation?externalData=all&amp;mapData=all&amp;modalities=Any">Lyft 3D Detection Challenge</a>
                                ), NeurIPS 2019
                            </li>
                            <li>Hong Kong PhD Fellowship (HKPFS), 2019</li>
                            <li>Chu Kochen Scholarship (Highest scholarship at Zhejiang University), 2018</li>
                            <li>Top 10 Students of ZJU (Highest honor for 5 undergraduates/graduates), 2018</li>
                            <li>National Scholarship (1.5%), 2017-2018</li>
                            <li>First Prize in Physics Competition for Undergraduate, 2017</li>
                        </ul>
                        <h2 id="teaching">Teaching</h2>
                        <ul>
                            <li>Computer Vision (Undergraduate Course), Winter 2018 @ ZJU</li>
                            <li>IERG2080: Introduction to Systems Programming, Fall 2020 @ CUHK</li>
                            <li>IERG2470B/ESTR2308: Probability Models and Applications (Elite Students), Spring 2021 @ CUHK</li>
                        </ul>
                        <h2 id="miscellaneous">Miscellaneous</h2>
                        <p>
                            <strong>Academic Services</strong>
                            <br/>I served as a reviewer for CVPR, ICCV, ECCV, CoRL, NeurIPS, ICLR, ICML, WACV, IJCV, TVCG.
                        </p>
                        <p>
                            <strong>Hobbies</strong>
                            <br/>
                            Love: üèÄBasketball (I am a big fan of <a href="https://en.wikipedia.org/wiki/Stephen_Curry">Stephen Curry</a>
                            and <a href="https://en.wikipedia.org/wiki/Tracy_McGrady">Tracy McGrady</a>
                            ), üéµmusic/üé§singing and good at üñåÔ∏èChinese calligraphy (learned from <a href="https://baike.baidu.com/item/%E9%A9%AC%E8%89%AF%E8%BE%B0/5438872">MA Liangchen</a>
                            and <a href="https://baike.baidu.com/item/%E9%A9%AC%E5%96%84%E5%8F%8C/5954206">MA Shanshuang</a>
                            ).
                        </p>
                    </section>
                    <footer class="page__meta"></footer>
                </div>
            </article>
        </div>
        <div class="page__footer">
            <footer>
                <!-- start custom footer snippets -->
                <a href="/sitemap/">Sitemap</a>
                <!-- end custom footer snippets -->
                <div class="page__footer-follow">
                    <ul class="social-icons">
                        <li>
                            <strong>Follow:</strong>
                        </li>
                        <li>
                            <a href="http://github.com/Tai-Wang">
                                <i class="fab fa-github" aria-hidden="true"></i>
                                GitHub
                            </a>
                        </li>
                        <li>
                            <a href="https://zhaoyanglyu.github.io/feed.xml">
                                <i class="fa fa-fw fa-rss-square" aria-hidden="true"></i>
                                Feed
                            </a>
                        </li>
                    </ul>
                </div>
                <div class="page__footer-copyright">
                    &copy;2023 Zhaoyang Lyu. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a>
                    &amp;<a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>
                    , a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>
                    .
                </div>
            </footer>
        </div>
        <script src="https://zhaoyanglyu.github.io/assets/js/main.min.js"></script>
        <script>
            (function(i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function() {
                    (i[r].q = i[r].q || []).push(arguments)
                }
                ,
                i[r].l = 1 * new Date();
                a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            }
            )(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
            ga('create', '', 'auto');
            ga('send', 'pageview');
        </script>
    </body>
</html>

